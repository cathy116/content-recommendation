{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data in chunks to avoid memory issues\n",
    "def load_dataset(file_lists, prefix_path, chunk_size=10000):\n",
    "    df_dict = {}\n",
    "    for file in file_lists:\n",
    "        try:\n",
    "            df_chunks = []\n",
    "            total_records = 0\n",
    "\n",
    "            for chunk in pd.read_json(prefix_path + file, lines=True, chunksize=chunk_size):\n",
    "                df_chunks.append(chunk)\n",
    "                total_records += chunk.shape[0]\n",
    "\n",
    "            df = pd.concat(df_chunks, ignore_index=True)\n",
    "            df_dict[file] = df\n",
    "            print(f\"Total records in {file}: {df.shape[0]}.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Timestamps to strings in the dataset\n",
    "def convert_timestamp_to_str(df, date_columns):\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S') if pd.notnull(x) else None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into business_details and related tables in batches\n",
    "def insert_business_data(df_business, conn, batch_size=10000):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    for i in range(0, len(df_business), batch_size):\n",
    "        batch = df_business.iloc[i:i + batch_size]\n",
    "\n",
    "        # Insert business details\n",
    "        cursor.executemany('''INSERT OR IGNORE INTO business_details \n",
    "                              (business_id, name, address, city, state, postal_code, latitude, longitude, stars, review_count, is_open)\n",
    "                              VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
    "                           batch[['business_id', 'name', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars', 'review_count', 'is_open']].values.tolist())\n",
    "\n",
    "        # Insert categories\n",
    "        for _, row in batch.iterrows():\n",
    "            categories = row['categories'].split(', ') if row['categories'] else []\n",
    "            cursor.executemany('INSERT OR IGNORE INTO business_categories (business_id, category) VALUES (?, ?)', \n",
    "                               [(row['business_id'], cat) for cat in categories])\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert review data\n",
    "def insert_review_data(df_review, conn, batch_size=10000):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    # Convert 'date' to string\n",
    "    df_review = convert_timestamp_to_str(df_review, ['date'])\n",
    "\n",
    "    for i in range(0, len(df_review), batch_size):\n",
    "        batch = df_review.iloc[i:i + batch_size]\n",
    "        cursor.executemany('''INSERT OR IGNORE INTO review_data \n",
    "                              (review_id, user_id, business_id, stars, date, text, useful, funny, cool)\n",
    "                              VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
    "                           batch[['review_id', 'user_id', 'business_id', 'stars', 'date', 'text', 'useful', 'funny', 'cool']].values.tolist())\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert user data \n",
    "def insert_user_data(df_user, conn, batch_size=10000):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    # Convert 'yelping_since' to string\n",
    "    # df_user = convert_timestamp_to_str(df_user, ['yelping_since'])\n",
    "\n",
    "    for i in range(0, len(df_user), batch_size):\n",
    "        batch = df_user.iloc[i:i + batch_size]\n",
    "        cursor.executemany('''INSERT OR IGNORE INTO user_data \n",
    "                              (user_id, name, review_count, yelping_since, useful, funny, cool, fans, average_stars)\n",
    "                              VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
    "                           batch[['user_id', 'name', 'review_count', 'yelping_since', 'useful', 'funny', 'cool', 'fans', 'average_stars']].values.tolist())\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert tip data\n",
    "def insert_tip_data(df_tip, conn, batch_size=10000):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('BEGIN TRANSACTION')\n",
    "\n",
    "    # Convert 'date' to string\n",
    "    df_tip = convert_timestamp_to_str(df_tip, ['date'])\n",
    "\n",
    "    for i in range(0, len(df_tip), batch_size):\n",
    "        batch = df_tip.iloc[i:i + batch_size]\n",
    "        cursor.executemany('''INSERT OR IGNORE INTO tip_data \n",
    "                              (user_id, business_id, text, date, compliment_count)\n",
    "                              VALUES (?, ?, ?, ?, ?)''',\n",
    "                           batch[['user_id', 'business_id', 'text', 'date', 'compliment_count']].values.tolist())\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables for Business, Review, User, and Tip data\n",
    "def create_tables(conn):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create table for business details\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS business_details (\n",
    "                        business_id TEXT PRIMARY KEY,\n",
    "                        name TEXT,\n",
    "                        address TEXT,\n",
    "                        city TEXT,\n",
    "                        state TEXT,\n",
    "                        postal_code TEXT,\n",
    "                        latitude REAL,\n",
    "                        longitude REAL,\n",
    "                        stars REAL,\n",
    "                        review_count INTEGER,\n",
    "                        is_open INTEGER\n",
    "                    )''')\n",
    "\n",
    "    # Create table for business categories\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS business_categories (\n",
    "                        business_id TEXT,\n",
    "                        category TEXT,\n",
    "                        FOREIGN KEY (business_id) REFERENCES business_details(business_id)\n",
    "                    )''')\n",
    "\n",
    "    # Create table for reviews\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS review_data (\n",
    "                        review_id TEXT PRIMARY KEY,\n",
    "                        user_id TEXT,\n",
    "                        business_id TEXT,\n",
    "                        stars INTEGER,\n",
    "                        date TEXT,\n",
    "                        text TEXT,\n",
    "                        useful INTEGER,\n",
    "                        funny INTEGER,\n",
    "                        cool INTEGER,\n",
    "                        FOREIGN KEY (business_id) REFERENCES business_details(business_id),\n",
    "                        FOREIGN KEY (user_id) REFERENCES user_data(user_id)\n",
    "                    )''')\n",
    "\n",
    "    # Create table for users\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS user_data (\n",
    "                        user_id TEXT PRIMARY KEY,\n",
    "                        name TEXT,\n",
    "                        review_count INTEGER,\n",
    "                        yelping_since TEXT,\n",
    "                        useful INTEGER,\n",
    "                        funny INTEGER,\n",
    "                        cool INTEGER,\n",
    "                        fans INTEGER,\n",
    "                        average_stars REAL\n",
    "                    )''')\n",
    "\n",
    "    # Create table for tips\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS tip_data (\n",
    "                        user_id TEXT,\n",
    "                        business_id TEXT,\n",
    "                        text TEXT,\n",
    "                        date TEXT,\n",
    "                        compliment_count INTEGER,\n",
    "                        FOREIGN KEY (business_id) REFERENCES business_details(business_id),\n",
    "                        FOREIGN KEY (user_id) REFERENCES user_data(user_id)\n",
    "                    )''')\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in sampled_yelp_academic_dataset_business.json: 78059.\n",
      "Total records in sampled_yelp_academic_dataset_review.json: 980418.\n",
      "Total records in sampled_yelp_academic_dataset_user.json: 229447.\n",
      "Total records in sampled_yelp_academic_dataset_tip.json: 173085.\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "folder_path = '../../data/'\n",
    "prefix_path = folder_path + 'raw_datasets/yelp/'\n",
    "file_list = [\n",
    "    \"sampled_yelp_academic_dataset_business.json\",\n",
    "    \"sampled_yelp_academic_dataset_review.json\",\n",
    "    \"sampled_yelp_academic_dataset_user.json\",\n",
    "    \"sampled_yelp_academic_dataset_tip.json\"\n",
    "]\n",
    "\n",
    "# Load the datasets in chunks\n",
    "df_dict = load_dataset(file_list, prefix_path)\n",
    "\n",
    "# Split the datasets\n",
    "df_business = df_dict[\"sampled_yelp_academic_dataset_business.json\"]\n",
    "df_review = df_dict[\"sampled_yelp_academic_dataset_review.json\"]\n",
    "df_user = df_dict[\"sampled_yelp_academic_dataset_user.json\"]\n",
    "df_tip = df_dict[\"sampled_yelp_academic_dataset_tip.json\"]\n",
    "\n",
    "# Create connections for separate database files\n",
    "db_path_business = '../../data/processed_data/yelp_data/yelp_business_data.db'\n",
    "db_path_review = '../../data/processed_data/yelp_data/yelp_review_data.db'\n",
    "db_path_user = '../../data/processed_data/yelp_data/yelp_user_data.db'\n",
    "db_path_tip = '../../data/processed_data/yelp_data/yelp_tip_data.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department Stores, Shopping, Fashion, Home & Garden, Electronics, Furniture Stores\n",
      "\n",
      "Restaurants, Food, Bubble Tea, Coffee & Tea, Bakeries\n",
      "\n",
      "Department Stores, Shopping, Fashion\n"
     ]
    }
   ],
   "source": [
    "print(df_business['categories'][0])\n",
    "print()\n",
    "print(df_business['categories'][1])\n",
    "print()\n",
    "print(df_business['categories'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_business = sqlite3.connect(db_path_business)\n",
    "conn_review = sqlite3.connect(db_path_review)\n",
    "conn_user = sqlite3.connect(db_path_user)\n",
    "conn_tip = sqlite3.connect(db_path_tip)\n",
    "\n",
    "# Create tables\n",
    "create_tables(conn_business)\n",
    "create_tables(conn_review)\n",
    "create_tables(conn_user)\n",
    "create_tables(conn_tip)\n",
    "\n",
    "# Insert data in batches\n",
    "insert_business_data(df_business, conn_business)\n",
    "insert_review_data(df_review, conn_review)\n",
    "insert_user_data(df_user, conn_user)\n",
    "insert_tip_data(df_tip, conn_tip)\n",
    "\n",
    "# Close connections\n",
    "conn_business.close()\n",
    "conn_review.close()\n",
    "conn_user.close()\n",
    "conn_tip.close()\n",
    "\n",
    "print(\"Data has been successfully stored in the databases.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content-recommendation-0SgTkEMC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
